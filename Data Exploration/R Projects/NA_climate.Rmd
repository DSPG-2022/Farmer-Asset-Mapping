---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```  

```{r}
#install.packages("inborutils", repos = c(inbo = "https://inbo.r-universe.dev", CRAN = "https://cloud.r-project.org"))
```


```{r}
#options(stringsAsFactors = FALSE)
library(ncdf4) 
library(raster)
library(tidyverse)
library(jsonlite)
library(httr)
library(rlist)
library(lubridate)
library(urltools)
library(inborutils)
library(rgdal)
library(maps)
library(mapdata)
library(sp)
library(rgeos)
```

```{r}
#Trying out one link first

#Coordinates: 42.038534290775225,-93.85498251613917

url_json <- "https://mesonet.agron.iastate.edu/iemre/multiday/2020-04-01/2020-10-31/42.038534290775225/-93.85498251613917/json"

# get the raw json into R
#raw_json <- httr::GET(url_json) %>% httr::content()

#Get raw json and into a dataframe
#jdata <- read_json(url_json, simplifyVector = TRUE)

btc <- jsonlite::fromJSON(url_json)

# get column names
colnames(btc$data)

```  

```{r}
btc
```

```{r}
#btc

df <- as.data.frame(btc)

df
```  
```{r}
#Rename columns

colnames(df) = c("date","mrms_precip_in","prism_precip_in","daily_high_f","12z_high_f","climate_daily_high_f","daily_low_f"  ,"12z_low_f","climate_daily_low_f","daily_precip_in","12z_precip_in","climate_daily_precip_in")

df
```  

```{r}
summary <- df %>% group_by(date)%>% summarize(sum_mrms_precip_in = sum(mrms_precip_in),sum_prism_precip_in = sum(prism_precip_in),mean_daily_high_f = mean(daily_high_f),mean_12z_high_f = mean(`12z_high_f`),mean_climate_daily_high_f = mean(climate_daily_high_f),mean_daily_low_f = mean(daily_low_f),mean_12z_low_f = mean(`12z_low_f`),mean_climate_daily_low_f = mean(climate_daily_low_f),sum_daily_precip_in = sum(daily_precip_in),sum_12z_precip_in = sum(df["12z_precip_in"]),sum_climate_daily_precip_in = sum(climate_daily_precip_in)) 

as.data.frame(summary)
```  
```{r}
# pluck and chuck provide a more strict version of [[
# and can subset by exact name or position

#purrr::pluck(btc$data, 'date')

df <- df %>% mutate(date = ymd(df$date))  
df# Print updated data
```


```{r}
#Fixed date column

summary_new <- df %>% mutate(month = format(date, "%m"), year = format(date, "%Y")) %>%
group_by(month, year) %>% summarize(sum_mrms_precip_in = sum(mrms_precip_in),sum_prism_precip_in = sum(prism_precip_in),mean_daily_high_f = mean(daily_high_f),mean_12z_high_f = mean(`12z_high_f`),mean_climate_daily_high_f = mean(climate_daily_high_f),mean_daily_low_f = mean(daily_low_f),mean_12z_low_f = mean(`12z_low_f`),mean_climate_daily_low_f = mean(climate_daily_low_f),sum_daily_precip_in = sum(daily_precip_in),sum_12z_precip_in = sum(`12z_precip_in`),sum_climate_daily_precip_in = sum(climate_daily_precip_in)) 

as.data.frame(summary_new)
```

```{r}
#Step 4
summary_new %>% ggplot(aes(x = month, y = mean_daily_high_f, fill = month)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    labs(
        x = "Month",
        y = "Average Daily High",
        title = paste(
            "Average Daily High(April-October 2020)"
        )
    )
```  

```{r}
# Basic line plot with points
ggplot(data=summary_new, aes(x=month, y=mean_climate_daily_high_f, group=1)) +
  geom_line()+
  geom_point()

```


```{r}
#  r web / r json - json to csv in r - saving it for later
write.csv(summary_new,"D:/Downloads/aproct_2020_clim.csv",row.names = FALSE)

```  


```{r}
base_url <- "https://mesonet.agron.iastate.edu/iemre/"

target_request <- "multiday/"
lat <- 42.038534290775225
lon <- -93.85498251613917
end_of_url <- "json"

#create a list of dates to concatenate to url
#dates <- c(2015-04-01,2015-10-31,2016-04-01,2016-10-31,2017-04-01,2017-10-31,2018-04-01,2018-10-31,2019-04-01,2019-10-31,2021-04-01,2021-10-31)

#create a list of dates to concatenate to url
start_dates = as.Date(c("2015-04-01", "2016-04-01", "2017-04-01", "2018-04-01", "2019-04-01","2020-04-01","2021-04-01"))

end_dates = as.Date(c("2015-10-31", "2016-10-31", "2017-10-31", "2018-10-31", "2019-10-31", "2020-10-31","2021-10-31"))

#Create empty list to store url's
url_list <-list()

#Loop through the start and end dates. First date is the start date, second date is the end date. Dates are paired.
#url format is: https://mesonet.agron.iastate.edu/iemre/multiday/start_dates/end_dates/lat/lon/json
 
#Create empty dataframe
df <- data.frame()

for (i in 1:length(start_dates)) {
  for (j in 1:length(end_dates)) {
    if (i == j) {
      url <- paste0(base_url, target_request, as.Date(start_dates[i]), "/", as.Date(end_dates[j]), "/", lat, "/", lon, "/", end_of_url)
      #Store the url in a list
      url_list <- c(url_list, url)
      print(url)
      data <- as.data.frame(jsonlite::fromJSON(url))
      df <- rbind(df,data)
    }
  }
}


```  



```{r}
#data_df
#Save dataframe to csv file
write.csv(df,"D:/Downloads/2015_2021_clim.csv",row.names = FALSE)
```

```{r}
#Coordinates: 42.038534290775225,-93.85498251613917

url_json <- "https://api.weather.gov/points/42.0385,-93.855"

weather <- jsonlite::fromJSON(url_json)

#class(weather)
weather
```
```{r}
#Get url from weather$properties$forecast and then get the json (Daily forecast)
url_daily <- noquote(weather$properties$forecast)

daily_forecast <- jsonlite::fromJSON(url_daily)

daily_forecast

```

```{r}
#Get url from weather$properties$forecastHourly and then get the json (Hourly forecast)
url_hour <- noquote(weather$properties$forecastHourly)

hour_forecast <- jsonlite::fromJSON(url_hour)

hour_forecast
```

```{r}
df <- as.data.frame(tif_test, xy = TRUE)
```

```{r}
nlayers(tif_test)
```  
```{r}
ncname <- "cfsv2_tmean_wk1234.nc"

ncin <- nc_open(ncname)

print(ncin)
```
```{r}
lat <- ncvar_get(ncin,"lat")
lat_units <- ncatt_get(ncin,"lat","units")

lon <- ncvar_get(ncin,"lon")
lon_units <- ncatt_get(ncin,"lon","units")

head(lat)

head(lon)

#'hasatt'means ‘has attribute’
lat_units
lon_units
```  
```{r}
#Variable to explore
var_target <- "tmean"

tmp_array <- ncvar_get(ncin,var_target)
 
dim(tmp_array)
```
```{r}
#Missing values
fillvalue <- ncatt_get(ncin,var_target,"_FillValue")

tmp_array[tmp_array==fillvalue$value] <- NA
```  

```{r}
# reshape the array into vector
tmp_vec_long <- as.vector(tmp_array)
length(tmp_vec_long)
```
```{r}
nlon <- dim(lon)
nlat <- dim(lat)
# reshape the vector into a matrix
tmp_mat <- matrix(tmp_vec_long, nrow=nlon*nlat)
dim(tmp_mat)
```
```{r}
# create a dataframe
lonlat <- as.matrix(expand.grid(lon,lat))
tmp_df <- data.frame(cbind(lonlat,tmp_mat))
names(tmp_df) <- c("lon","lat","temp")
head(na.omit(tmp_df))
```  


```{r}
write.csv(tmp_df,"D:/Downloads/28_temp_forecast.csv",row.names = FALSE)
```


```{r}

```

