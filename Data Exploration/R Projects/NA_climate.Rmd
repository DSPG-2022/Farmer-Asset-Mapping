---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```  

```{r}
install.packages("urltools")
```


```{r}
library(tidyverse)
library(jsonlite)
library(httr)
library(rlist)
library(lubridate)
library(urltools)
```

```{r}
#Trying out one link first

#Coordinates: 42.038534290775225,-93.85498251613917

url_json <- "https://mesonet.agron.iastate.edu/iemre/multiday/2020-04-01/2020-10-31/42.038534290775225/-93.85498251613917/json"

# get the raw json into R
#raw_json <- httr::GET(url_json) %>% httr::content()

#Get raw json and into a dataframe
#jdata <- read_json(url_json, simplifyVector = TRUE)

btc <- jsonlite::fromJSON(url_json)

# get column names
colnames(btc$data)

```  
```{r}
#btc

df <- as.data.frame(btc)

df
```  
```{r}
#Rename columns

colnames(df) = c("date","mrms_precip_in","prism_precip_in","daily_high_f","12z_high_f","climate_daily_high_f","daily_low_f"  ,"12z_low_f","climate_daily_low_f","daily_precip_in","12z_precip_in","climate_daily_precip_in")

df
```  

```{r}
summary <- df %>% group_by(date)%>% summarize(sum_mrms_precip_in = sum(mrms_precip_in),sum_prism_precip_in = sum(prism_precip_in),mean_daily_high_f = mean(daily_high_f),mean_12z_high_f = mean(`12z_high_f`),mean_climate_daily_high_f = mean(climate_daily_high_f),mean_daily_low_f = mean(daily_low_f),mean_12z_low_f = mean(`12z_low_f`),mean_climate_daily_low_f = mean(climate_daily_low_f),sum_daily_precip_in = sum(daily_precip_in),sum_12z_precip_in = sum(df["12z_precip_in"]),sum_climate_daily_precip_in = sum(climate_daily_precip_in)) 

as.data.frame(summary)
```  
```{r}
# pluck and chuck provide a more strict version of [[
# and can subset by exact name or position

#purrr::pluck(btc$data, 'date')

df <- df %>% mutate(date = ymd(df$date))  
df# Print updated data
```


```{r}
#Fixed date column

summary_new <- df %>% mutate(month = format(date, "%m"), year = format(date, "%Y")) %>%
group_by(month, year) %>% summarize(sum_mrms_precip_in = sum(mrms_precip_in),sum_prism_precip_in = sum(prism_precip_in),mean_daily_high_f = mean(daily_high_f),mean_12z_high_f = mean(`12z_high_f`),mean_climate_daily_high_f = mean(climate_daily_high_f),mean_daily_low_f = mean(daily_low_f),mean_12z_low_f = mean(`12z_low_f`),mean_climate_daily_low_f = mean(climate_daily_low_f),sum_daily_precip_in = sum(daily_precip_in),sum_12z_precip_in = sum(`12z_precip_in`),sum_climate_daily_precip_in = sum(climate_daily_precip_in)) 

as.data.frame(summary_new)
```

```{r}
#Step 4
summary_new %>% ggplot(aes(x = month, y = mean_daily_high_f, fill = month)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    labs(
        x = "Month",
        y = "Average Daily High",
        title = paste(
            "Average Daily High(April-October 2020)"
        )
    )
```  

```{r}
# Basic line plot with points
ggplot(data=summary_new, aes(x=month, y=mean_climate_daily_high_f, group=1)) +
  geom_line()+
  geom_point()

```


```{r}
#  r web / r json - json to csv in r - saving it for later
write.csv(summary_new,"D:/Downloads/aproct_2020_clim.csv",row.names = FALSE)

```  

```{r}

```



```{r}
base_url <- "https://mesonet.agron.iastate.edu/iemre/"

target_request <- "multiday/"
lat <- 42.038534290775225
lon <- -93.85498251613917
end_of_url <- "json"

#create a list of dates to concatenate to url
#dates <- c(2015-04-01,2015-10-31,2016-04-01,2016-10-31,2017-04-01,2017-10-31,2018-04-01,2018-10-31,2019-04-01,2019-10-31,2021-04-01,2021-10-31)

#create a list of dates to concatenate to url
start_dates = as.Date(c("2015-04-01", "2016-04-01", "2017-04-01", "2018-04-01", "2019-04-01", "2021-04-01"))

end_dates = as.Date(c("2015-10-31", "2016-10-31", "2017-10-31", "2018-10-31", "2019-10-31", "2021-10-31"))


#Loop through the start and end dates. First date is the start date, second date is the end date. Dates are paired.
#url format is: https://mesonet.agron.iastate.edu/iemre/multiday/start_dates/end_dates/42.038534290775225/-93.85498251613917/json

while (length(start_dates) > 0) {
  start_date <- start_dates[1]
  end_date <- end_dates[1]
  url <- paste0(base_url, target_request, as.Date(start_dates[i]), "/", as.Date(end_dates[j]), "/", lat, "/", lon, "/", end_of_url)
  #Create a list of urls
  urls <- c(url, urls)
  start_dates <- start_dates[-1]
  end_dates <- end_dates[-1]
  #Store data in a dataframe
  data <- jsonlite::fromJSON(url)
  #Store data in a dataframe
  df <- dataframe(data)
    #Append data to the dataframe
    df_list <- c(df_list, df)
}


```

```{r}
df
```

